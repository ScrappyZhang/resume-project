{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from scipy.sparse.linalg import norm as sparse_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resumes based on experience level\n",
    "\n",
    "What are the key linguistic indicators of experience level on a resume? By inspecting resumes of different experience we can answer this question.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "After analyzing these resumes, we can look at characteristic words for low and high experience and then identify \"upgrades\", i.e. words with a similar meaning that are characteristically more \"experieneced\". If you're just here for the recommendations (with manual curation) go no further, here they are:\n",
    "\n",
    "+ \"assisted with\" -> \"provided support for\"\n",
    "+ \"helping\" or \"assisting\" -> \"supporting\"\n",
    "+ \"problem\" -> \"need\"\n",
    "+ \"good\" or \"great\" -> \"quality\"\n",
    "+ \"organize\" -> \"coordinate\"\n",
    "+ \"customer\" -> \"client\"\n",
    "+ \"task\" -> \"project\"\n",
    "+ \"academic\" -> \"technical\"\n",
    "+ \"communication\" -> \"management\"\n",
    "+ \"cleaning\" -> \"maintenance\"\n",
    "\n",
    "### So, how did we get there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source\n",
    "\n",
    "Data was taken from a leading resume board. Resumes were marked with experience level. Job titles were taken from the Bureau of Labor Statistics Occupational Outlook Handbook (BLS OOH). All job titles were searched. Documents were saved into json files based on job titles. The sections of the resume relating to job experience were saved in the json files for analysis.\n",
    "\n",
    "After saving the file, we can export the corpus of job descriptions for analysis. These functions extract the json files and return a corpus and a corresponding list of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all():\n",
    "\t\"\"\"Create a corpus and list of attributes for documents for Tfidf Fun\"\"\"\n",
    "\tpath = 'C:/Users/matth/OneDrive/Desktop/Data/records'\n",
    "\tfiles = os.listdir(path)\n",
    "\tfiles = [file for file in files if file not in ('.DS_Store','old')]\n",
    "\tattr_list = []\n",
    "\tcorpus = []\n",
    "\tcorp_set = set()\n",
    "\tfor file in files:\n",
    "\t\twith open(path+'/'+file) as f:\n",
    "\t\t\tattr_list, corpus  = proc_file(f,file,corpus,attr_list,corp_set)\n",
    "\treturn attr_list,corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_file(f,file,corpus,attr_list,corp_set):\n",
    "\tfor line in f:\n",
    "\t\tjline = json.loads( line.strip() )\n",
    "\t\ttext = proc_jline(jline)\n",
    "\t\tif not jline['title']: ##filter out empty titles\n",
    "\t\t\tcontinue\n",
    "\t\tif text:\n",
    "\t\t\tobj= {'level':jline['level']}\n",
    "\t\t\tobj['title'] = file.split('.')[0]\n",
    "\t\t\tif text not in corp_set:\n",
    "\t\t\t\tcorp_set.add(text)\n",
    "\t\t\t\tcorpus.append(text)\n",
    "\t\t\t\tattr_list.append(obj)\n",
    "\treturn attr_list, corpus\n",
    "\n",
    "def proc_jline(jline):\n",
    "\tclean_text_list = [ clean_text( we['description'], stem=False )  for we in jline['work_experience'] ]\n",
    "\ttext = ' '.join( ct for ct in clean_text_list if len(ct)<5000 ) ## Filter out overlong descriptions\n",
    "\treturn text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s,stem=False):\n",
    "\t\"\"\"Clean out the text\"\"\"\n",
    "\tret = s.lower()\n",
    "\tret = re.sub(r'[^a-z ]',' ',ret)\n",
    "\tret = re.sub(r' +',' ',ret).strip()\n",
    "\tret = re.sub(r'see more occupations related to this (activity|skill|task)','',ret)\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list,corpus = process_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a little peak at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': '3-5 years', 'title': 'accountants and auditors'}\n",
      "employment roberts and chaplin registered auditors umhlali kwa zulu natal south africa january december progressed from an associate to a senior associate i have performed audit engagements non audit assurance engagements and agreed upon procedure engagements on diverse client industries including manufacturing mining retail recreational and non profit organizations during the training contract i achieved all saica south african institute of chartered accountants competencies required related to auditing and accounting as well as residual skills related to taxation internal audit corporate governance and managerial accounting activities performed during my work experience are application and compliance with international financial reporting standards ifrs ifrs for small and medium sized entities ifrs for sme s and the international standards on auditing isa s reporting on assessment of internal controls and deficiencies identified in accounting procedures evaluation and reporting on monthly management accounts budgets and reconciliations as well as analysis on profitability identification of business and financial risks preparation of financial statements in accordance with ifrs preparation of client tax liability in compliance with the income tax act for the south african revenue services sars professional communication which include the leading of various internal and external meetings and drafting reports regarding the conclusion of audit engagements performing inventory counts and drafting of stock reports maintaining up to date records of timesheets leadership and management experience as senior associate create maintain favorable client relations responsible for the engagement team organization and supervision of audit teams training of junior staff members project management planning and completion of audit engagements drafting of audit budgets review of working papers and conclusions ensuring all engagement related activities such as acceptance and continuance billings and paper file archiving requirements were complied with adhered to\n",
      "20023 20023\n"
     ]
    }
   ],
   "source": [
    "print(attr_list[0])\n",
    "print(corpus[0])\n",
    "print(len(attr_list),len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must featurize our data set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tfidf(corpus):\n",
    "\ttfidf_vectorizer = TfidfVectorizer( max_features=8000, stop_words='english', ngram_range=(1, 1), min_df=0.03 )\n",
    "\ttfidf = tfidf_vectorizer.fit_transform( corpus )\n",
    "\tcount_vectorizer = CountVectorizer( max_features=8000, stop_words='english', ngram_range=(1, 1), min_df=0.03 )\n",
    "\tcount = count_vectorizer.fit_transform( corpus )\n",
    "\ttfidf_labels = tfidf_vectorizer.get_feature_names()\n",
    "\t# tfidf_label_dict = { label:ind for ind,label in enumerate( tfidf_labels ) }\n",
    "\tcount_labels = count_vectorizer.get_feature_names()\n",
    "\tcount_label_dict = { label:ind for ind,label in enumerate( count_labels ) }\n",
    "\t# count_label_indices = [ tfidf_label_dict[label] for label in count_labels if label in tfidf_label_dict]\n",
    "\tnew_count = np.zeros( tfidf.shape )\n",
    "\tfor k,l in enumerate( tfidf_labels ):\n",
    "\t\tif l in count_label_dict:\n",
    "\t\t\tnew_count[ : , k ] = count[ : , count_label_dict[ l ] ].todense().reshape( new_count[ : , k ].shape )\n",
    "\treturn {\n",
    "\t\t'tfidf':tfidf,\n",
    "\t\t'count':scipy.sparse.csr_matrix(new_count),\n",
    "\t\t'labels':tfidf_labels,\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrected_counts(tfidf_dict,attr_list, counttype='tfidf', correct_for_number_collected=False):\n",
    "\toccs = set( a['title'] for a in attr_list )\n",
    "\tlevels = set( a['level'] for a in attr_list )\n",
    "\tcount_dict={}\n",
    "\tfor occ in occs:\n",
    "\t\tsubset = [a for a in attr_list if a['title']==occ ]\n",
    "\t\tfor level in levels:\n",
    "\t\t\tcount_dict[ (occ,level) ] = len( [ a for a in subset if a['level']==level ] )\n",
    "\tret = np.zeros( tfidf_dict[counttype].shape )\n",
    "\tfor i in range( ret.shape[0] ):\n",
    "\t\tcorrection_factor = 1.\n",
    "\t\tif correct_for_number_collected:\n",
    "\t\t\tcorrection_factor = count_dict[ ( attr_list[i]['title'] , attr_list[i]['level'] ) ]\n",
    "\t\tret[i,:] = 1. * ( tfidf_dict[counttype][i,:] ).todense() / correction_factor\n",
    "\treturn ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dict = get_tfidf(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function to find differences between different experience levels with respect to TFIDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_differences(tfidf_dict,level1,level2, attr_list, typename=\"count\"):\n",
    "\toverall1 = np.array( tfidf_dict[typename][ [ k for k,o in enumerate(attr_list) if o['level']==level1 ] ,:].mean(axis=0) )[0]\n",
    "\toverall2 = np.array( tfidf_dict[typename][ [ k for k,o in enumerate(attr_list) if o['level']==level2 ] ,:].mean(axis=0) )[0]\n",
    "\treturn sorted( [ ( v1-v2 , l )\n",
    "\t\t\t\tfor l,v1,v2 in zip(tfidf_dict['labels'],overall1,overall2) ]\n",
    "\t\t\t\t, key=None, reverse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033\n",
      "[(-0.020470263352602595, 'responsible'), (-0.019076986210144718, 'training'), (-0.018795251310089675, 'management'), (-0.018471566563729162, 'staff'), (-0.01777832420012951, 'sales')]\n",
      "[(0.005875586244732587, 'learned'), (0.0063766111790492, 'helped'), (0.006606537122600925, 'patients'), (0.00832738190732854, 'clean')]\n"
     ]
    }
   ],
   "source": [
    "result = get_max_differences(tfidf_dict,'Less than 1 year','More than 10 years',attr_list,typename='tfidf')\n",
    "\n",
    "print(len(result))\n",
    "print(result[:5])\n",
    "print(result[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experienced_words.txt','w') as f:\n",
    "\tfor score,word in result[:100]:\n",
    "\t\tf.write(word+'\\t'+str(score)+'\\n')\n",
    "\n",
    "with open('novice_words.txt','w') as f:\n",
    "\tfor score,word in result[-100:-1]:\n",
    "\t\tf.write(word+'\\t'+str(score)+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed some manual editing on these files to remove words that were too specific. So now how do we get upgrade recommendations from novice to experienced? One way would be manually--or we can try something else.\n",
    "\n",
    "## Word Vectors\n",
    "\n",
    "Let's use pretrained word vectors (GLOVE vectors) to go from novice words to the experienced. The file is about 600MB but you can find it to download on google (\"glove vectors\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experienced_words_edited.txt') as f:\n",
    "    exp_words = [line.strip().split('\\t')[0] for line in f]\n",
    "with open('novice_words_edited.txt') as f:\n",
    "    nov_words = [line.strip().split('\\t')[0] for line in f]\n",
    "all_words = set(exp_words) | set(nov_words)\n",
    "\n",
    "def get_vector_dict():\n",
    "    vector_dict = {}\n",
    "    with open('C:/Users/matth/OneDrive/Desktop/Data/glove.6B.200d.txt',encoding=\"utf8\") as f:\n",
    "        counter = 0\n",
    "        while counter<300000:\n",
    "#             if counter%10000==0: print(counter)\n",
    "            counter+=1\n",
    "            line = next(f)\n",
    "            elements = line.strip().split(' ')\n",
    "            word = elements[0]\n",
    "            if word not in all_words:\n",
    "                continue\n",
    "            array = np.array( [float(n) for n in elements[1:]] )\n",
    "            array = array/np.linalg.norm(array)\n",
    "            vector_dict[word] = array\n",
    "            if len(vector_dict) == len(all_words):\n",
    "                break\n",
    "    return vector_dict\n",
    "\n",
    "vector_dict=get_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "online -> business, services, network, applications, programs\n",
      "project -> projects, development, construction, program, plan\n",
      "floor -> level, new, construction, installed, included\n",
      "event -> annual, team, performance, special, included\n",
      "filing -> claims, employees, employee, reports, clients\n",
      "rooms -> facility, installed, provide, provided, equipment\n",
      "day -> new, annual, special, included, including\n",
      "job -> hiring, employees, business, staff, needs\n",
      "national -> team, administration, department, program, new\n",
      "check -> required, ensure, provide, needs, monitoring\n",
      "change -> needs, policies, plan, new, control\n",
      "solving -> issues, developing, implementation, development, needs\n",
      "conference -> annual, team, development, issues, new\n",
      "present -> provide, provided, required, new, needs\n",
      "tests -> required, procedures, develop, performance, level\n",
      "preparing -> planning, plan, training, responsible, provide\n",
      "cleaned -> repair, installed, maintenance, equipment, implemented\n",
      "work -> projects, needs, required, business, new\n",
      "excellent -> quality, performance, provide, provided, technical\n",
      "products -> product, quality, equipment, company, business\n",
      "reading -> level, required, included, quality, performance\n",
      "phone -> services, network, business, company, equipment\n",
      "computer -> systems, equipment, applications, programs, business\n",
      "assisting -> responsible, personnel, developing, training, oversee\n",
      "took -> managed, included, including, team, control\n",
      "days -> including, new, reports, required, included\n",
      "ability -> needs, manage, develop, required, ensure\n",
      "store -> product, company, vendor, business, department\n",
      "human -> development, responsible, developing, related, internal\n",
      "college -> training, programs, program, team, business\n",
      "paperwork -> documentation, procedures, required, requirements, payroll\n",
      "american -> including, included, new, business, include\n",
      "place -> new, ensure, managed, team, level\n",
      "organizing -> planning, responsible, coordinated, oversee, training\n",
      "keeping -> ensure, maintained, needs, responsible, monitoring\n",
      "packaging -> product, quality, company, equipment, business\n",
      "environment -> development, ensure, developing, management, policies\n",
      "attended -> training, annual, including, included, staff\n",
      "social -> policies, issues, development, support, needs\n",
      "life -> new, business, needs, including, related\n",
      "sure -> needs, ensure, required, provide, manage\n",
      "people -> including, million, responsible, employees, needs\n",
      "cleaning -> maintenance, repair, equipment, construction, procedures\n",
      "academic -> technical, programs, training, level, business\n",
      "years -> including, new, million, included, business\n",
      "experience -> needs, training, provide, performance, quality\n",
      "charge -> responsible, claims, department, planning, special\n",
      "making -> including, new, business, responsible, included\n",
      "assembly -> new, support, required, installed, control\n",
      "good -> quality, needs, performance, business, provide\n",
      "great -> needs, including, new, quality, included\n",
      "learning -> training, developed, programs, develop, program\n",
      "setting -> plan, new, planning, including, requirements\n",
      "problem -> needs, issues, control, internal, related\n",
      "different -> include, including, developed, related, included\n",
      "items -> equipment, related, included, include, special\n",
      "position -> control, team, support, level, administration\n",
      "basic -> provide, requirements, required, needs, quality\n",
      "pressure -> level, control, support, needs, internal\n",
      "patients -> required, procedures, needs, clients, provide\n",
      "responsibilities -> duties, requirements, operational, responsible, needs\n",
      "accomplishments -> performance, goals, administration, programs, projects\n",
      "research -> development, management, developed, program, projects\n",
      "taking -> including, control, responsible, included, new\n",
      "analyzing -> monitoring, reports, developing, reporting, responsible\n",
      "working -> needs, business, developed, employees, program\n",
      "tasks -> duties, operational, requirements, required, implementation\n",
      "presented -> included, special, provided, review, new\n",
      "assisted -> responsible, supervised, training, personnel, including\n",
      "helping -> manage, managed, support, provide, needs\n",
      "using -> developed, equipment, provide, systems, provided\n",
      "resulting -> related, internal, product, required, production\n",
      "organized -> coordinated, planning, responsible, annual, special\n",
      "learned -> training, needs, developed, team, staff\n",
      "communication -> systems, services, technical, provide, direct\n",
      "assistant -> department, staff, supervisor, team, management\n",
      "student -> program, employee, programs, training, employees\n",
      "customers -> clients, employees, business, company, services\n",
      "clean -> ensure, needs, quality, provide, projects\n",
      "summer -> annual, training, new, program, team\n",
      "used -> provided, developed, provide, equipment, special\n",
      "children -> including, programs, program, included, provide\n",
      "analyzed -> reports, implemented, developed, related, review\n",
      "data -> applications, systems, reports, provide, provided\n",
      "helped -> managed, manage, support, provide, develop\n",
      "worked -> managed, staff, department, developed, company\n"
     ]
    }
   ],
   "source": [
    "exp_mat = np.array( [vector_dict[word] for word in exp_words] )\n",
    "nov_mat = np.array( [vector_dict[word] for word in nov_words] )\n",
    "\n",
    "sims = np.dot( exp_mat, nov_mat.transpose() )\n",
    "for k,word in enumerate(nov_words):\n",
    "\ttemp_sim = sims[:,k]\n",
    "\tindices = list(np.argsort(temp_sim)[::-1])\n",
    "\ttop_n_words = [exp_words[n] for n in indices[:5]]\n",
    "\tprint(word+' -> '+', '.join(top_n_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there you have it! These arrows point from novice to the most similar experienced words as candidates for substitution. There are certainly some strange anomalies here like project vs. projects. I'll chalk this up to a couple things:\n",
    "\n",
    "1) Maybe experienced people have more responsibilities (plural vs. one).\n",
    "\n",
    "2) Could be random sampling error--we may be able to get a stronger recommendation if we use a supervised learning technique like logistic regression and control the variance of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
